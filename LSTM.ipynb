{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ6e5z69dxmj",
        "outputId": "bcf9c40a-7473-4f79-bce2-ab3d61601ace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import gc\n",
        "from PIL import Image\n",
        "from textwrap import wrap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import spacy\n",
        "from tensorflow.python.keras import models, layers, optimizers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import bz2\n",
        "import re\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "Njn3dthNesfu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/irfinalproject/file.csv')"
      ],
      "metadata": {
        "id": "EFjXr0KgfO3R"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_labels, test_labels, train_texts , test_texts = train_test_split(df['Label'],df['Text'] ,\n",
        "                                   random_state=104, \n",
        "                                   test_size=0.25, \n",
        "                                   shuffle=True)"
      ],
      "metadata": {
        "id": "9jVopBRLf0S0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NON_ALPHANUM = re.compile(r'[\\W]')\n",
        "NON_ASCII = re.compile(r'[^a-z0-1\\s]')\n",
        "def normalize_texts(texts):\n",
        "\n",
        "    normalized_texts = []\n",
        "    \n",
        "    for text in texts:\n",
        "        lower = text.lower()\n",
        "        no_punctuation = NON_ALPHANUM.sub(r' ', lower)\n",
        "        no_non_ascii = NON_ASCII.sub(r'', no_punctuation)\n",
        "        normalized_texts.append(no_non_ascii)\n",
        "    return normalized_texts\n",
        "        \n",
        "train_texts = normalize_texts(train_texts)\n",
        "test_texts = normalize_texts(test_texts)"
      ],
      "metadata": {
        "id": "vO5BkL9vgBMG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts_Bert = train_texts\n",
        "train_labels_Bert = train_labels\n",
        "test_texts_Bert = test_texts\n",
        "test_labels_Bert = test_labels\n",
        "train_reviews = train_texts"
      ],
      "metadata": {
        "id": "tpo4aQXqgIOH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    train_texts, train_labels, random_state=57643892, test_size=0.2)"
      ],
      "metadata": {
        "id": "CBzP0fJBgJQB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_FEATURES = 12000\n",
        "#Tokenize texts\n",
        "tokenizer = Tokenizer(num_words=MAX_FEATURES)\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "train_texts = tokenizer.texts_to_sequences(train_texts)\n",
        "val_texts = tokenizer.texts_to_sequences(val_texts)\n",
        "test_texts = tokenizer.texts_to_sequences(test_texts)"
      ],
      "metadata": {
        "id": "XMW23X7AgNW5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = max(len(train_ex) for train_ex in train_texts)\n",
        "#Add padding\n",
        "train_texts = pad_sequences(train_texts, maxlen=MAX_LENGTH)\n",
        "val_texts = pad_sequences(val_texts, maxlen=MAX_LENGTH)\n",
        "test_texts = pad_sequences(test_texts, maxlen=MAX_LENGTH)"
      ],
      "metadata": {
        "id": "fMzm6UT7goWl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_lstm_model():\n",
        "    sequences = layers.Input(shape=(MAX_LENGTH,))\n",
        "    embedded = layers.Embedding(MAX_FEATURES, 64)(sequences)\n",
        "    x = layers.LSTM(32, return_sequences=True)(embedded)\n",
        "    x = layers.GlobalMaxPool1D()(x)\n",
        "    x = layers.Dense(16, activation='relu')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    predictions = layers.Dense(1, activation='sigmoid')(x)\n",
        "    model = models.Model(inputs=sequences, outputs=predictions)\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "    \n",
        "lstm_model = build_lstm_model()"
      ],
      "metadata": {
        "id": "7FIpr97Tgrw4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lstm_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pgy4LW6sgtEH",
        "outputId": "c7aa9ab5-97b0-4422-e7a3-e91b3e5d6eac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 868)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 868, 64)           768000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 868, 32)           12416     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 780,961\n",
            "Trainable params: 780,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.fit(\n",
        "    train_texts, \n",
        "    train_labels, \n",
        "    batch_size=128,\n",
        "    epochs=2,\n",
        "    validation_data=(val_texts, val_labels), )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbZucAmOgvxx",
        "outputId": "512db677-677b-42c7-c605-77824e8a3d32"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "235/235 [==============================] - 334s 1s/step - loss: 0.4930 - accuracy: 0.7504 - val_loss: 0.3192 - val_accuracy: 0.8657\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 323s 1s/step - loss: 0.2703 - accuracy: 0.8933 - val_loss: 0.3061 - val_accuracy: 0.8739\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1071ac9e80>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = lstm_model.predict(test_texts)\n",
        "print('Accuracy score: {:0.4}'.format(accuracy_score(test_labels, 1 * (preds > 0.5))))\n",
        "print('F1 score: {:0.4}'.format(f1_score(test_labels, 1 * (preds > 0.5))))\n",
        "print('ROC AUC score: {:0.4}'.format(roc_auc_score(test_labels, preds)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY_HpNqFgz57",
        "outputId": "2b8c1d32-ab7b-4e13-9d7f-cd45b45e62bb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.8735\n",
            "F1 score: 0.8909\n",
            "ROC AUC score: 0.9423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.save_weights('/content/drive/MyDrive/irfinalproject/lstm.h5')"
      ],
      "metadata": {
        "id": "ZLf7JtzajqnZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = build_lstm_model()\n",
        "model1.load_weights('/content/drive/MyDrive/irfinalproject/lstm.h5')"
      ],
      "metadata": {
        "id": "LpwuEkPJkdzm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"Good product, must buy !!\"\n",
        "input_text = tokenizer.texts_to_sequences([input_text])\n",
        "input_text = pad_sequences(input_text, maxlen=MAX_LENGTH)\n",
        "#prediction = lstm_model.predict(input_text)\n",
        "prediction = model1.predict(input_text)\n",
        "label = 1 if prediction > 0.5 else 0\n",
        "print(label)"
      ],
      "metadata": {
        "id": "rFE7btgNkgnI",
        "outputId": "b795dacd-fc68-4ba1-9db9-b0619186f91f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    }
  ]
}